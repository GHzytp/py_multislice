<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.4" />
<title>pyms.utils.torch_utils API documentation</title>
<meta name="description" content="A set of utility functions for working with pytorch tensors." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pyms.utils.torch_utils</code></h1>
</header>
<section id="section-intro">
<p>A set of utility functions for working with pytorch tensors.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;A set of utility functions for working with pytorch tensors.&#34;&#34;&#34;
import torch
import numpy as np
from itertools import product


re = np.s_[..., 0]
im = np.s_[..., 1]


def iscomplex(a: torch.Tensor):
    &#34;&#34;&#34;Return True if a is complex, False otherwise.&#34;&#34;&#34;
    return a.shape[-1] == 2


def check_complex(A):
    &#34;&#34;&#34;Raise a RuntimeWarning if tensor A is not complex.&#34;&#34;&#34;
    for a in A:
        if not iscomplex(a):
            raise RuntimeWarning(
                &#34;taking complex_mul of non-complex tensor! a.shape &#34; + str(a.shape)
            )


def to_complex(real, imag=None):
    &#34;&#34;&#34;Convert real and imaginary tensors to a complex tensor.&#34;&#34;&#34;
    if imag is None:
        return torch.stack(
            [real, torch.zeros(real.size(), dtype=real.dtype, device=real.device)], -1
        )
    else:
        return torch.stack([real, imag], -1)


def get_device(device_type=None):
    &#34;&#34;&#34;Initialize device cuda if available, CPU if no cuda is available.&#34;&#34;&#34;
    if device_type is None and torch.cuda.is_available():
        device = torch.device(&#34;cuda&#34;)
    elif device_type is None:
        device = torch.device(&#34;cpu&#34;)
    else:
        device = torch.device(device_type)
    return device


def complex_matmul(a: torch.Tensor, b: torch.Tensor, conjugate=False) -&gt; torch.Tensor:
    &#34;&#34;&#34;
    Complex matrix multiplication of tensors a and b.

    Pass conjugate = True to conjugate tensor b in the multiplication.
    &#34;&#34;&#34;
    check_complex([a, b])
    are = a[re]
    aim = a[im]
    bre = b[re]
    bim = b[im]
    if conjugate:
        real = are @ bre + aim @ bim
        imag = -are @ bim + aim @ bre
    else:
        real = are @ bre - aim @ bim
        imag = are @ bim + aim @ bre

    return torch.stack([real, imag], -1)


def complex_mul(a: torch.Tensor, b: torch.Tensor, conjugate=False) -&gt; torch.Tensor:
    &#34;&#34;&#34;
    Complex array multiplication of tensors a and b.

    Pass conjugate = True to conjugate tensor b in the multiplication.
    &#34;&#34;&#34;
    check_complex([a, b])
    are = a[re]
    aim = a[im]
    bre = b[re]
    bim = b[im]
    if conjugate:
        real = are * bre + aim * bim
        imag = -are * bim + aim * bre
    else:
        real = are * bre - aim * bim
        imag = are * bim + aim * bre

    return torch.stack([real, imag], -1)


def torch_c_exp(angle):
    &#34;&#34;&#34;Calculate exp(1j*angle).&#34;&#34;&#34;
    if angle.size()[-1] != 2:
        # Case of a real exponent
        result = torch.zeros(*angle.shape, 2, dtype=angle.dtype, device=angle.device)
        result[re] = torch.cos(angle)
        result[im] = torch.sin(angle)
    else:
        # Case of a complex valued exponent
        exp = torch.exp(-angle[im])
        result = torch.zeros(*angle.shape, dtype=angle.dtype, device=angle.device)
        result[re] = exp * torch.cos(angle[re])
        result[im] = exp * torch.sin(angle[re])
    return result


def sinc(x):
    &#34;&#34;&#34;Calculate the sinc function ie. sin(pi x)/(pi x).&#34;&#34;&#34;
    y = torch.where(torch.abs(x) &lt; 1.0e-20, torch.tensor([1.0e-20], dtype=x.dtype), x)
    return torch.sin(np.pi * y) / np.pi / y


def ensure_torch_array(array, dtype=torch.float, device=None):
    &#34;&#34;&#34;
    Ensure that the input array is a pytorch tensor.

    Converts to a pytorch array if input is a numpy array and do nothing if the
    input is a pytorch tensor
    &#34;&#34;&#34;
    from .. import (
        layered_structure_propagators,
        layered_structure_transmission_function,
    )

    if device is None:
        device = get_device(device)
    if isinstance(array, torch.Tensor):
        return array.to(device)
    elif isinstance(array, layered_structure_transmission_function):
        for i in range(len(array.Ts)):
            array.Ts[i] = array.Ts[i].to(device)
        return array
    elif isinstance(array, layered_structure_propagators):
        for i in range(len(array.Ps)):
            array.Ps[i] = array.Ps[i].to(device)
        return array
    else:
        if np.iscomplexobj(np.asarray(array)):
            return cx_from_numpy(np.asarray(array), dtype=dtype, device=device)
        else:
            return torch.from_numpy(np.asarray(array)).type(dtype).to(device)


def amplitude(r):
    &#34;&#34;&#34;
    Calculate the amplitude of a complex tensor.

    If the tensor is not complex then calculate square.
    &#34;&#34;&#34;
    if r.size(-1) == 2:
        return r[..., 0] * r[..., 0] + r[..., 1] * r[..., 1]
    else:
        return r * r


# def roll_n(X, axis, n):
#     &#34;&#34;&#34;Roll a pytorch tensor X n entries along a given axis.&#34;&#34;&#34;
#     f_idx = tuple(
#         slice(None, None, None) if i != axis % X.dim() else slice(0, n, None)
#         for i in range(X.dim())
#     )
#     b_idx = tuple(
#         slice(None, None, None) if i != axis % X.dim() else slice(n, None, None)
#         for i in range(X.dim())
#     )
#     front = X[f_idx]
#     back = X[b_idx]
#     return torch.cat([back, front], axis)


def cx_from_numpy(
    x: np.array, dtype=torch.float32, device=get_device()
) -&gt; torch.Tensor:
    &#34;&#34;&#34;
    Turn a complex numpy array into the required pytorch array format.

    Parameters
    ----------
    x : complex np.ndarray
        A complex numpy array

    Keyword arguments
    -----------------
    dtype : torch.dtype
        The datatype of the output array
    device : torch.device
        The device (CPU or GPU) of the output array
    &#34;&#34;&#34;
    if &#34;complex&#34; in str(x.dtype):
        out = torch.zeros(*x.shape, 2)
        out[re] = torch.from_numpy(x.real)
        out[im] = torch.from_numpy(x.imag)
    else:
        if x.shape[-1] != 2:
            out = torch.zeros(x.shape + (2,))
            out[re] = torch.from_numpy(x.real)
        else:
            out = torch.zeros(x.shape + (2,))
            out[re] = torch.from_numpy(x[re])
            out[im] = torch.from_numpy(x[im])
    return out.to(device).type(dtype)


def cx_to_numpy(x: torch.Tensor) -&gt; np.ndarray:
    &#34;&#34;&#34;Convert a complex pytorch tensor to a complex numpy array.&#34;&#34;&#34;
    check_complex(x)

    return x[re].cpu().numpy() + 1j * x[im].cpu().numpy()


def fftfreq(n, dtype=torch.float, device=torch.device(&#34;cpu&#34;)):
    &#34;&#34;&#34;
    Generate an array of Fourier coordinates in units of pixels.

    Same as numpy.fft.fftfreq(n)*n but for a torch array.
    &#34;&#34;&#34;
    return (torch.arange(n, dtype=dtype, device=device) + n // 2) % n - n // 2


def torch_dtype_to_numpy(dtype):
    &#34;&#34;&#34;Convert a torch datatype to a numpy datatype.&#34;&#34;&#34;
    scratch_array = torch.zeros(1, dtype=dtype)
    return scratch_array.cpu().numpy().dtype


def fourier_shift_array_1d(
    y, posn, dtype=torch.float, device=torch.device(&#34;cpu&#34;), units=&#34;pixels&#34;
):
    &#34;&#34;&#34;Apply Fourier shift theorem for sub-pixel shift to a 1 dimensional array.&#34;&#34;&#34;
    ramp = torch.empty(y, 2, dtype=dtype, device=device)
    ky = 2 * np.pi * fftfreq(y) * posn
    if units == &#34;pixels&#34;:
        ky /= y
    ramp[..., 0] = torch.cos(ky)
    ramp[..., 1] = -torch.sin(ky)
    return ramp


def fourier_shift_torch(
    array,
    posn,
    dtype=torch.float32,
    device=torch.device(&#34;cpu&#34;),
    qspace_in=False,
    qspace_out=False,
    units=&#34;pixels&#34;,
):
    &#34;&#34;&#34;
    Apply Fourier shift theorem for sub-pixel shifts to array.

    Parameters
    -----------
    array : torch.tensor (...,Y,X,2)
        Complex array to be Fourier shifted
    posn : torch.tensor (K x 2) or (2,)
        Shift(s) to be applied
    &#34;&#34;&#34;
    if not qspace_in:
        array = torch.fft(array, signal_ndim=2)

    array = complex_mul(
        array,
        fourier_shift_array(
            array.size()[-3:-1],
            posn,
            dtype=array.dtype,
            device=array.device,
            units=units,
        ),
    )

    if qspace_out:
        return array

    return torch.ifft(array, signal_ndim=2)


def fourier_shift_array(
    size, posn, dtype=torch.float, device=torch.device(&#34;cpu&#34;), units=&#34;pixels&#34;
):
    &#34;&#34;&#34;
    Create Fourier shift theorem array to (pixel) position given by list posn.

    Parameters
    ----------
    size : array_like
        size of the array (Y,X)
    posn : array_like
        can be a K x 2 array to give a K x Y x X shift arrays
    posn
    &#34;&#34;&#34;
    # Get number of dimensions
    nn = len(posn.shape)

    # Get size of array
    y, x = size

    if nn == 1:
        # Make y ramp exp(-2pi i ky y)
        yramp = fourier_shift_array_1d(
            y, posn[0], units=units, dtype=dtype, device=device
        )

        # Make y ramp exp(-2pi i kx x)
        xramp = fourier_shift_array_1d(
            x, posn[1], units=units, dtype=dtype, device=device
        )

        # Multiply both arrays together, view statements for
        # appropriate broadcasting to 2D
        return complex_mul(yramp.view(y, 1, 2), xramp.view(1, x, 2))
    else:
        K = posn.shape[0]
        # Make y ramp exp(-2pi i ky y)
        yramp = torch.empty(K, y, 2, dtype=dtype, device=device)
        ky = (
            2
            * np.pi
            * fftfreq(y, dtype=dtype, device=device).view(1, y)
            * posn[:, 0].view(K, 1)
        )
        if units == &#34;pixels&#34;:
            ky /= y
        yramp[..., 0] = torch.cos(ky)
        yramp[..., 1] = -torch.sin(ky)

        # Make y ramp exp(-2pi i kx x)
        xramp = torch.empty(K, x, 2, dtype=dtype, device=device)
        kx = (
            2
            * np.pi
            * fftfreq(x, dtype=dtype, device=device).view(1, x)
            * posn[:, 1].view(K, 1)
        )
        if units == &#34;pixels&#34;:
            kx /= x

        xramp[..., 0] = torch.cos(kx)
        xramp[..., 1] = -torch.sin(kx)

        # Multiply both arrays together, view statements for
        # appropriate broadcasting to 2D
        return complex_mul(yramp.view(K, y, 1, 2), xramp.view(K, 1, x, 2))


def crop_window_to_periodic_indices(win, shape):
    &#34;&#34;&#34;
    Create indices for a rectangular subset of a larger array.

    If indices exceed the size of the larger array then these indices will wrap
    around to the other side of the grid providing two or more rectangular
    subsets of the larger array. Designed to be used in conjunction with
    the torch.narrow function to choose subsets of the square array to evaluate
    the PRISM algorithm on.

    Assumes that the requested window is smaller than the array size

    Parameters
    ----------
    win : (4,) array_like
        contains (y0,y,x0,x) the lower y index and y length and lower x index
        and x length
    shape : (2,) array_like
        Shape of the larger array

    Examples
    --------
    &gt;&gt;&gt;&gt; crop_window_to_periodic_indices([2,2,1,3],[5,5])
    (([2,2],[1,3]),)
    &gt;&gt;&gt;&gt; crop_window_to_periodic_indices([-1,3,1,3],[5,5])
    (([4,1],[1,3]),([0,2],[1,3]))
    &gt;&gt;&gt;&gt; crop_window_to_periodic_indices([4,4,1,3],[5,5])
    (([4,1],[1,3]),([0,3],[1,3]))
    &gt;&gt;&gt;&gt; list(crop_window_to_periodic_indices([4,4,3,3],[5,5]))
    (([4,1],[3,2]),([0,3],[3,2]),([4,1],[0,1]),([0,3],[0,1]))
    &#34;&#34;&#34;

    def oneDindices(start, step, bound):
        if start + step &gt; bound - 1:
            return [start, bound - start], [0, start + step - bound]
        elif start &lt; 0:
            return [start % bound, bound - start % bound], [0, (start + step) % bound]
        else:
            return [[start, step]]

    y = oneDindices(*win[:2], shape[0])
    x = oneDindices(*win[2:], shape[1])

    return tuple(product(y, x))


def crop_window_to_flattened_indices_torch(indices: torch.Tensor, shape: list):
    &#34;&#34;&#34;
    Create (flattened) indices for a rectangular subset of a larger array.

    Useful, for example for scattering matrix calculations where only a rectangular
    subset of the array is used in the PRISM interpolation routine

    Array indices exceeding the bounds of the array are wrapped to be consistent
    with periodic boundary conditions.

    Parameters
    ----------
    indices : torch.Tensor
        The centers of each of the cropping windows
    shape : array_like
        Size of the cropping windows

    Examples
    --------
    &gt;&gt;&gt; indices = torch.as_tensor([[2,3,4],[1,2,3]])
    &gt;&gt;&gt; gridshape = [4,4]
    &gt;&gt;&gt; win = [3,3]
    &gt;&gt;&gt; grid = torch.zeros(gridshape,dtype=torch.Long)
    tensor([[0, 0, 0, 0],
            [0, 0, 0, 0],
            [0, 0, 0, 0],
            [0, 0, 0, 0]])
    &gt;&gt;&gt; grid = grid.flatten()
    &gt;&gt;&gt; ind = pyms.utils.crop_window_to_flattened_indices_torch(indices,gridshape)
    &gt;&gt;&gt; grid[ind] = 1
    &gt;&gt;&gt; grid.view(gridshape)
    tensor([[0, 1, 1, 1],
            [0, 0, 0, 0],
            [0, 1, 1, 1],
            [0, 1, 1, 1]])
    &#34;&#34;&#34;
    xind = torch.as_tensor(indices[-1]).view(1, len(indices[-1])) % shape[-1]
    yind = torch.as_tensor(indices[-2]).view(len(indices[-2]), 1) % shape[-2]
    return (xind + yind * shape[-1]).flatten().type(torch.LongTensor)


def crop_to_bandwidth_limit_torch(
    array: torch.Tensor,
    limit=2 / 3,
    qspace_in=True,
    qspace_out=True,
    norm=&#34;conserve_L2&#34;,
):
    &#34;&#34;&#34;Crop an array to its bandwidth limit (remove superfluous array entries).&#34;&#34;&#34;
    # Check if array is complex or not
    complx = iscomplex(array)

    # Get array shape, taking into account final dimension of size 2 if the array
    # is complex
    gridshape = array.shape[-2 - int(complx) :][:2]

    # New shape of final dimensions
    newshape = tuple([int(round(gridshape[i] * limit)) for i in range(2)])

    return fourier_interpolate_2d_torch(
        array, newshape, norm=norm, qspace_in=qspace_in, qspace_out=qspace_out
    )


def size_of_bandwidth_limited_array(shape):
    &#34;&#34;&#34;Get the size of an array after band-width limiting.&#34;&#34;&#34;
    return list(crop_to_bandwidth_limit_torch(torch.zeros(*shape)).size())


def detect(detector, diffraction_pattern):
    &#34;&#34;&#34;
    Apply a detector to a diffraction pattern.

    Calculates the signal in a diffraction pattern detector even if the size
    of the diffraction pattern and the detector are mismatched, assumes that
    the zeroth coordinate in reciprocal space is in the top-left hand corner
    of the array.
    &#34;&#34;&#34;
    minsize = min(detector.size()[-2:], diffraction_pattern.size()[-2:])

    wind = [fftfreq(minsize[i], torch.long, detector.device) for i in [0, 1]]
    Dwind = crop_window_to_flattened_indices_torch(wind, detector.size())
    DPwind = crop_window_to_flattened_indices_torch(wind, diffraction_pattern.size())
    return torch.sum(
        detector.flatten(-2, -1)[:, None, Dwind]
        * diffraction_pattern.flatten(-2, -1)[None, :, DPwind],
        dim=-1,
    )


def fourier_interpolate_2d_torch(
    ain, shapeout, norm=&#34;conserve_val&#34;, qspace_in=False, qspace_out=False
):
    &#34;&#34;&#34;
    Fourier interpolation of array ain to shape shapeout.

    If shapeout is smaller than ain.shape then Fourier downsampling is
    performed

    Parameters
    ----------
    ain : (...,Ny,Nx,2) torch.tensor
        Input array
    shapeout : (2,) array_like
        Shape of output array
    norm : str, optional  {&#39;conserve_val&#39;,&#39;conserve_norm&#39;,&#39;conserve_L1&#39;}
        Normalization of output. If &#39;conserve_val&#39; then array values are preserved
        if &#39;conserve_norm&#39; L2 norm is conserved under interpolation and if
        &#39;conserve_L1&#39; L1 norm is conserved under interpolation
    qspace_in : bool, optional
        If True expect a Fourier space input, otherwise (default) expect a
        real space input
    qspace_out : bool, optional
        If True return a Fourier space output, otherwise (default) return in
        real space
    &#34;&#34;&#34;
    dtype = ain.dtype
    inputComplex = iscomplex(ain)
    # Make input complex
    aout = torch.zeros(
        ain.shape[: -2 - int(inputComplex)] + (np.prod(shapeout), 2),
        dtype=dtype,
        device=ain.device,
    )

    # Get input dimensions
    npiyin, npixin = ain.size()[-2 - int(inputComplex) :][:2]
    npiyout, npixout = shapeout

    # Get Fourier interpolation masks
    # PyTorch does not yet do element-wise logic operations, so we have to do
    # this bit in numpy. Additionally, in Windows pytorch does not support
    # bool types so we have to convert this to a unsigned 8-bit integer.
    from .numpy_utils import Fourier_interpolation_masks

    maskin, maskout = [
        torch.from_numpy(x).flatten()
        for x in Fourier_interpolation_masks(npiyin, npixin, npiyout, npixout)
    ]

    # Now transfer over Fourier coefficients from input to output array
    if inputComplex:
        ain_ = ain
    else:
        ain_ = to_complex(ain)

    if not qspace_in:
        ain_ = torch.fft(ain_, signal_ndim=2)

    aout[..., maskout, :] = ain_.flatten(-3, -2)[..., maskin, :]

    # Fourier transform result with appropriate normalization
    if norm == &#34;conserve_val&#34;:
        factor = npiyout * npixout / (npiyin * npixin)
    elif norm == &#34;conserve_norm&#34;:
        factor = np.sqrt(npiyout * npixout / (npiyin * npixin))
    else:
        factor = 1

    # Fourier transform result with appropriate normalization
    aout = factor * aout.reshape(
        ain.shape[: -2 - int(inputComplex)] + tuple(shapeout) + (2,)
    )

    if not qspace_out:
        aout = torch.ifft(aout, signal_ndim=2)

    # Return correct array data type
    if inputComplex:
        return aout
    return aout[re]


def crop_torch(arrayin, shapeout):
    &#34;&#34;&#34;
    Crop the last two dimensions of arrayin to grid size shapeout.

    For entries of shapeout which are larger than the shape of the input array,
    perform zero-padding.
    &#34;&#34;&#34;
    C = iscomplex(arrayin)

    # Number of dimensions in input array
    ndim = arrayin.ndim

    # Number of dimensions not covered by shapeout (ie not to be cropped)
    nUntouched = ndim - 2 - C

    # Shape of output array
    shapeout_ = arrayin.shape[:nUntouched] + tuple(shapeout)
    if C:
        shapeout_ += (2,)

    arrayout = torch.zeros(shapeout_, dtype=arrayin.dtype, device=arrayin.device)

    y, x = arrayin.shape[-2 - C :][:2]
    y_, x_ = shapeout[-2:]

    def indices(y, y_):
        if y &gt; y_:
            # Crop in y dimension
            y1, y2 = [(y - y_) // 2, (y + y_) // 2]
            y1_, y2_ = [0, y_]
        else:
            # Zero pad in y dimension
            y1, y2 = [0, y]
            y1_, y2_ = [(y_ - y) // 2, (y + y_) // 2]
        return y1, y2, y1_, y2_

    y1, y2, y1_, y2_ = indices(y, y_)
    x1, x2, x1_, x2_ = indices(x, x_)

    if C:
        arrayout[..., y1_:y2_, x1_:x2_, :] = arrayin[..., y1:y2, x1:x2, :]
    else:
        arrayout[..., y1_:y2_, x1_:x2_] = arrayin[..., y1:y2, x1:x2]

    return arrayout</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pyms.utils.torch_utils.amplitude"><code class="name flex">
<span>def <span class="ident">amplitude</span></span>(<span>r)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the amplitude of a complex tensor.</p>
<p>If the tensor is not complex then calculate square.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def amplitude(r):
    &#34;&#34;&#34;
    Calculate the amplitude of a complex tensor.

    If the tensor is not complex then calculate square.
    &#34;&#34;&#34;
    if r.size(-1) == 2:
        return r[..., 0] * r[..., 0] + r[..., 1] * r[..., 1]
    else:
        return r * r</code></pre>
</details>
</dd>
<dt id="pyms.utils.torch_utils.check_complex"><code class="name flex">
<span>def <span class="ident">check_complex</span></span>(<span>A)</span>
</code></dt>
<dd>
<div class="desc"><p>Raise a RuntimeWarning if tensor A is not complex.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_complex(A):
    &#34;&#34;&#34;Raise a RuntimeWarning if tensor A is not complex.&#34;&#34;&#34;
    for a in A:
        if not iscomplex(a):
            raise RuntimeWarning(
                &#34;taking complex_mul of non-complex tensor! a.shape &#34; + str(a.shape)
            )</code></pre>
</details>
</dd>
<dt id="pyms.utils.torch_utils.complex_matmul"><code class="name flex">
<span>def <span class="ident">complex_matmul</span></span>(<span>a: torch.Tensor, b: torch.Tensor, conjugate=False) ‑> torch.Tensor</span>
</code></dt>
<dd>
<div class="desc"><p>Complex matrix multiplication of tensors a and b.</p>
<p>Pass conjugate = True to conjugate tensor b in the multiplication.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def complex_matmul(a: torch.Tensor, b: torch.Tensor, conjugate=False) -&gt; torch.Tensor:
    &#34;&#34;&#34;
    Complex matrix multiplication of tensors a and b.

    Pass conjugate = True to conjugate tensor b in the multiplication.
    &#34;&#34;&#34;
    check_complex([a, b])
    are = a[re]
    aim = a[im]
    bre = b[re]
    bim = b[im]
    if conjugate:
        real = are @ bre + aim @ bim
        imag = -are @ bim + aim @ bre
    else:
        real = are @ bre - aim @ bim
        imag = are @ bim + aim @ bre

    return torch.stack([real, imag], -1)</code></pre>
</details>
</dd>
<dt id="pyms.utils.torch_utils.complex_mul"><code class="name flex">
<span>def <span class="ident">complex_mul</span></span>(<span>a: torch.Tensor, b: torch.Tensor, conjugate=False) ‑> torch.Tensor</span>
</code></dt>
<dd>
<div class="desc"><p>Complex array multiplication of tensors a and b.</p>
<p>Pass conjugate = True to conjugate tensor b in the multiplication.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def complex_mul(a: torch.Tensor, b: torch.Tensor, conjugate=False) -&gt; torch.Tensor:
    &#34;&#34;&#34;
    Complex array multiplication of tensors a and b.

    Pass conjugate = True to conjugate tensor b in the multiplication.
    &#34;&#34;&#34;
    check_complex([a, b])
    are = a[re]
    aim = a[im]
    bre = b[re]
    bim = b[im]
    if conjugate:
        real = are * bre + aim * bim
        imag = -are * bim + aim * bre
    else:
        real = are * bre - aim * bim
        imag = are * bim + aim * bre

    return torch.stack([real, imag], -1)</code></pre>
</details>
</dd>
<dt id="pyms.utils.torch_utils.crop_to_bandwidth_limit_torch"><code class="name flex">
<span>def <span class="ident">crop_to_bandwidth_limit_torch</span></span>(<span>array: torch.Tensor, limit=0.6666666666666666, qspace_in=True, qspace_out=True, norm='conserve_L2')</span>
</code></dt>
<dd>
<div class="desc"><p>Crop an array to its bandwidth limit (remove superfluous array entries).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def crop_to_bandwidth_limit_torch(
    array: torch.Tensor,
    limit=2 / 3,
    qspace_in=True,
    qspace_out=True,
    norm=&#34;conserve_L2&#34;,
):
    &#34;&#34;&#34;Crop an array to its bandwidth limit (remove superfluous array entries).&#34;&#34;&#34;
    # Check if array is complex or not
    complx = iscomplex(array)

    # Get array shape, taking into account final dimension of size 2 if the array
    # is complex
    gridshape = array.shape[-2 - int(complx) :][:2]

    # New shape of final dimensions
    newshape = tuple([int(round(gridshape[i] * limit)) for i in range(2)])

    return fourier_interpolate_2d_torch(
        array, newshape, norm=norm, qspace_in=qspace_in, qspace_out=qspace_out
    )</code></pre>
</details>
</dd>
<dt id="pyms.utils.torch_utils.crop_torch"><code class="name flex">
<span>def <span class="ident">crop_torch</span></span>(<span>arrayin, shapeout)</span>
</code></dt>
<dd>
<div class="desc"><p>Crop the last two dimensions of arrayin to grid size shapeout.</p>
<p>For entries of shapeout which are larger than the shape of the input array,
perform zero-padding.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def crop_torch(arrayin, shapeout):
    &#34;&#34;&#34;
    Crop the last two dimensions of arrayin to grid size shapeout.

    For entries of shapeout which are larger than the shape of the input array,
    perform zero-padding.
    &#34;&#34;&#34;
    C = iscomplex(arrayin)

    # Number of dimensions in input array
    ndim = arrayin.ndim

    # Number of dimensions not covered by shapeout (ie not to be cropped)
    nUntouched = ndim - 2 - C

    # Shape of output array
    shapeout_ = arrayin.shape[:nUntouched] + tuple(shapeout)
    if C:
        shapeout_ += (2,)

    arrayout = torch.zeros(shapeout_, dtype=arrayin.dtype, device=arrayin.device)

    y, x = arrayin.shape[-2 - C :][:2]
    y_, x_ = shapeout[-2:]

    def indices(y, y_):
        if y &gt; y_:
            # Crop in y dimension
            y1, y2 = [(y - y_) // 2, (y + y_) // 2]
            y1_, y2_ = [0, y_]
        else:
            # Zero pad in y dimension
            y1, y2 = [0, y]
            y1_, y2_ = [(y_ - y) // 2, (y + y_) // 2]
        return y1, y2, y1_, y2_

    y1, y2, y1_, y2_ = indices(y, y_)
    x1, x2, x1_, x2_ = indices(x, x_)

    if C:
        arrayout[..., y1_:y2_, x1_:x2_, :] = arrayin[..., y1:y2, x1:x2, :]
    else:
        arrayout[..., y1_:y2_, x1_:x2_] = arrayin[..., y1:y2, x1:x2]

    return arrayout</code></pre>
</details>
</dd>
<dt id="pyms.utils.torch_utils.crop_window_to_flattened_indices_torch"><code class="name flex">
<span>def <span class="ident">crop_window_to_flattened_indices_torch</span></span>(<span>indices: torch.Tensor, shape: list)</span>
</code></dt>
<dd>
<div class="desc"><p>Create (flattened) indices for a rectangular subset of a larger array.</p>
<p>Useful, for example for scattering matrix calculations where only a rectangular
subset of the array is used in the PRISM interpolation routine</p>
<p>Array indices exceeding the bounds of the array are wrapped to be consistent
with periodic boundary conditions.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>indices</code></strong> :&ensp;<code>torch.Tensor</code></dt>
<dd>The centers of each of the cropping windows</dd>
<dt><strong><code>shape</code></strong> :&ensp;<code>array_like</code></dt>
<dd>Size of the cropping windows</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="python">&gt;&gt;&gt; indices = torch.as_tensor([[2,3,4],[1,2,3]])
&gt;&gt;&gt; gridshape = [4,4]
&gt;&gt;&gt; win = [3,3]
&gt;&gt;&gt; grid = torch.zeros(gridshape,dtype=torch.Long)
tensor([[0, 0, 0, 0],
        [0, 0, 0, 0],
        [0, 0, 0, 0],
        [0, 0, 0, 0]])
&gt;&gt;&gt; grid = grid.flatten()
&gt;&gt;&gt; ind = pyms.utils.crop_window_to_flattened_indices_torch(indices,gridshape)
&gt;&gt;&gt; grid[ind] = 1
&gt;&gt;&gt; grid.view(gridshape)
tensor([[0, 1, 1, 1],
        [0, 0, 0, 0],
        [0, 1, 1, 1],
        [0, 1, 1, 1]])
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def crop_window_to_flattened_indices_torch(indices: torch.Tensor, shape: list):
    &#34;&#34;&#34;
    Create (flattened) indices for a rectangular subset of a larger array.

    Useful, for example for scattering matrix calculations where only a rectangular
    subset of the array is used in the PRISM interpolation routine

    Array indices exceeding the bounds of the array are wrapped to be consistent
    with periodic boundary conditions.

    Parameters
    ----------
    indices : torch.Tensor
        The centers of each of the cropping windows
    shape : array_like
        Size of the cropping windows

    Examples
    --------
    &gt;&gt;&gt; indices = torch.as_tensor([[2,3,4],[1,2,3]])
    &gt;&gt;&gt; gridshape = [4,4]
    &gt;&gt;&gt; win = [3,3]
    &gt;&gt;&gt; grid = torch.zeros(gridshape,dtype=torch.Long)
    tensor([[0, 0, 0, 0],
            [0, 0, 0, 0],
            [0, 0, 0, 0],
            [0, 0, 0, 0]])
    &gt;&gt;&gt; grid = grid.flatten()
    &gt;&gt;&gt; ind = pyms.utils.crop_window_to_flattened_indices_torch(indices,gridshape)
    &gt;&gt;&gt; grid[ind] = 1
    &gt;&gt;&gt; grid.view(gridshape)
    tensor([[0, 1, 1, 1],
            [0, 0, 0, 0],
            [0, 1, 1, 1],
            [0, 1, 1, 1]])
    &#34;&#34;&#34;
    xind = torch.as_tensor(indices[-1]).view(1, len(indices[-1])) % shape[-1]
    yind = torch.as_tensor(indices[-2]).view(len(indices[-2]), 1) % shape[-2]
    return (xind + yind * shape[-1]).flatten().type(torch.LongTensor)</code></pre>
</details>
</dd>
<dt id="pyms.utils.torch_utils.crop_window_to_periodic_indices"><code class="name flex">
<span>def <span class="ident">crop_window_to_periodic_indices</span></span>(<span>win, shape)</span>
</code></dt>
<dd>
<div class="desc"><p>Create indices for a rectangular subset of a larger array.</p>
<p>If indices exceed the size of the larger array then these indices will wrap
around to the other side of the grid providing two or more rectangular
subsets of the larger array. Designed to be used in conjunction with
the torch.narrow function to choose subsets of the square array to evaluate
the PRISM algorithm on.</p>
<p>Assumes that the requested window is smaller than the array size</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>win</code></strong> :&ensp;<code>(4,) array_like</code></dt>
<dd>contains (y0,y,x0,x) the lower y index and y length and lower x index
and x length</dd>
<dt><strong><code>shape</code></strong> :&ensp;<code>(2,) array_like</code></dt>
<dd>Shape of the larger array</dd>
</dl>
<h2 id="examples">Examples</h2>
<blockquote>
<blockquote>
<blockquote>
<blockquote>
<p>crop_window_to_periodic_indices([2,2,1,3],[5,5])
(([2,2],[1,3]),)
crop_window_to_periodic_indices([-1,3,1,3],[5,5])
(([4,1],[1,3]),([0,2],[1,3]))
crop_window_to_periodic_indices([4,4,1,3],[5,5])
(([4,1],[1,3]),([0,3],[1,3]))
list(crop_window_to_periodic_indices([4,4,3,3],[5,5]))
(([4,1],[3,2]),([0,3],[3,2]),([4,1],[0,1]),([0,3],[0,1]))</p>
</blockquote>
</blockquote>
</blockquote>
</blockquote></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def crop_window_to_periodic_indices(win, shape):
    &#34;&#34;&#34;
    Create indices for a rectangular subset of a larger array.

    If indices exceed the size of the larger array then these indices will wrap
    around to the other side of the grid providing two or more rectangular
    subsets of the larger array. Designed to be used in conjunction with
    the torch.narrow function to choose subsets of the square array to evaluate
    the PRISM algorithm on.

    Assumes that the requested window is smaller than the array size

    Parameters
    ----------
    win : (4,) array_like
        contains (y0,y,x0,x) the lower y index and y length and lower x index
        and x length
    shape : (2,) array_like
        Shape of the larger array

    Examples
    --------
    &gt;&gt;&gt;&gt; crop_window_to_periodic_indices([2,2,1,3],[5,5])
    (([2,2],[1,3]),)
    &gt;&gt;&gt;&gt; crop_window_to_periodic_indices([-1,3,1,3],[5,5])
    (([4,1],[1,3]),([0,2],[1,3]))
    &gt;&gt;&gt;&gt; crop_window_to_periodic_indices([4,4,1,3],[5,5])
    (([4,1],[1,3]),([0,3],[1,3]))
    &gt;&gt;&gt;&gt; list(crop_window_to_periodic_indices([4,4,3,3],[5,5]))
    (([4,1],[3,2]),([0,3],[3,2]),([4,1],[0,1]),([0,3],[0,1]))
    &#34;&#34;&#34;

    def oneDindices(start, step, bound):
        if start + step &gt; bound - 1:
            return [start, bound - start], [0, start + step - bound]
        elif start &lt; 0:
            return [start % bound, bound - start % bound], [0, (start + step) % bound]
        else:
            return [[start, step]]

    y = oneDindices(*win[:2], shape[0])
    x = oneDindices(*win[2:], shape[1])

    return tuple(product(y, x))</code></pre>
</details>
</dd>
<dt id="pyms.utils.torch_utils.cx_from_numpy"><code class="name flex">
<span>def <span class="ident">cx_from_numpy</span></span>(<span>x: <built-in function array>, dtype=torch.float32, device=device(type='cuda')) ‑> torch.Tensor</span>
</code></dt>
<dd>
<div class="desc"><p>Turn a complex numpy array into the required pytorch array format.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>complex np.ndarray</code></dt>
<dd>A complex numpy array</dd>
</dl>
<h2 id="keyword-arguments">Keyword Arguments</h2>
<p>dtype : torch.dtype
The datatype of the output array
device : torch.device
The device (CPU or GPU) of the output array</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cx_from_numpy(
    x: np.array, dtype=torch.float32, device=get_device()
) -&gt; torch.Tensor:
    &#34;&#34;&#34;
    Turn a complex numpy array into the required pytorch array format.

    Parameters
    ----------
    x : complex np.ndarray
        A complex numpy array

    Keyword arguments
    -----------------
    dtype : torch.dtype
        The datatype of the output array
    device : torch.device
        The device (CPU or GPU) of the output array
    &#34;&#34;&#34;
    if &#34;complex&#34; in str(x.dtype):
        out = torch.zeros(*x.shape, 2)
        out[re] = torch.from_numpy(x.real)
        out[im] = torch.from_numpy(x.imag)
    else:
        if x.shape[-1] != 2:
            out = torch.zeros(x.shape + (2,))
            out[re] = torch.from_numpy(x.real)
        else:
            out = torch.zeros(x.shape + (2,))
            out[re] = torch.from_numpy(x[re])
            out[im] = torch.from_numpy(x[im])
    return out.to(device).type(dtype)</code></pre>
</details>
</dd>
<dt id="pyms.utils.torch_utils.cx_to_numpy"><code class="name flex">
<span>def <span class="ident">cx_to_numpy</span></span>(<span>x: torch.Tensor) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Convert a complex pytorch tensor to a complex numpy array.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cx_to_numpy(x: torch.Tensor) -&gt; np.ndarray:
    &#34;&#34;&#34;Convert a complex pytorch tensor to a complex numpy array.&#34;&#34;&#34;
    check_complex(x)

    return x[re].cpu().numpy() + 1j * x[im].cpu().numpy()</code></pre>
</details>
</dd>
<dt id="pyms.utils.torch_utils.detect"><code class="name flex">
<span>def <span class="ident">detect</span></span>(<span>detector, diffraction_pattern)</span>
</code></dt>
<dd>
<div class="desc"><p>Apply a detector to a diffraction pattern.</p>
<p>Calculates the signal in a diffraction pattern detector even if the size
of the diffraction pattern and the detector are mismatched, assumes that
the zeroth coordinate in reciprocal space is in the top-left hand corner
of the array.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def detect(detector, diffraction_pattern):
    &#34;&#34;&#34;
    Apply a detector to a diffraction pattern.

    Calculates the signal in a diffraction pattern detector even if the size
    of the diffraction pattern and the detector are mismatched, assumes that
    the zeroth coordinate in reciprocal space is in the top-left hand corner
    of the array.
    &#34;&#34;&#34;
    minsize = min(detector.size()[-2:], diffraction_pattern.size()[-2:])

    wind = [fftfreq(minsize[i], torch.long, detector.device) for i in [0, 1]]
    Dwind = crop_window_to_flattened_indices_torch(wind, detector.size())
    DPwind = crop_window_to_flattened_indices_torch(wind, diffraction_pattern.size())
    return torch.sum(
        detector.flatten(-2, -1)[:, None, Dwind]
        * diffraction_pattern.flatten(-2, -1)[None, :, DPwind],
        dim=-1,
    )</code></pre>
</details>
</dd>
<dt id="pyms.utils.torch_utils.ensure_torch_array"><code class="name flex">
<span>def <span class="ident">ensure_torch_array</span></span>(<span>array, dtype=torch.float32, device=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Ensure that the input array is a pytorch tensor.</p>
<p>Converts to a pytorch array if input is a numpy array and do nothing if the
input is a pytorch tensor</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def ensure_torch_array(array, dtype=torch.float, device=None):
    &#34;&#34;&#34;
    Ensure that the input array is a pytorch tensor.

    Converts to a pytorch array if input is a numpy array and do nothing if the
    input is a pytorch tensor
    &#34;&#34;&#34;
    from .. import (
        layered_structure_propagators,
        layered_structure_transmission_function,
    )

    if device is None:
        device = get_device(device)
    if isinstance(array, torch.Tensor):
        return array.to(device)
    elif isinstance(array, layered_structure_transmission_function):
        for i in range(len(array.Ts)):
            array.Ts[i] = array.Ts[i].to(device)
        return array
    elif isinstance(array, layered_structure_propagators):
        for i in range(len(array.Ps)):
            array.Ps[i] = array.Ps[i].to(device)
        return array
    else:
        if np.iscomplexobj(np.asarray(array)):
            return cx_from_numpy(np.asarray(array), dtype=dtype, device=device)
        else:
            return torch.from_numpy(np.asarray(array)).type(dtype).to(device)</code></pre>
</details>
</dd>
<dt id="pyms.utils.torch_utils.fftfreq"><code class="name flex">
<span>def <span class="ident">fftfreq</span></span>(<span>n, dtype=torch.float32, device=device(type='cpu'))</span>
</code></dt>
<dd>
<div class="desc"><p>Generate an array of Fourier coordinates in units of pixels.</p>
<p>Same as numpy.fft.fftfreq(n)*n but for a torch array.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fftfreq(n, dtype=torch.float, device=torch.device(&#34;cpu&#34;)):
    &#34;&#34;&#34;
    Generate an array of Fourier coordinates in units of pixels.

    Same as numpy.fft.fftfreq(n)*n but for a torch array.
    &#34;&#34;&#34;
    return (torch.arange(n, dtype=dtype, device=device) + n // 2) % n - n // 2</code></pre>
</details>
</dd>
<dt id="pyms.utils.torch_utils.fourier_interpolate_2d_torch"><code class="name flex">
<span>def <span class="ident">fourier_interpolate_2d_torch</span></span>(<span>ain, shapeout, norm='conserve_val', qspace_in=False, qspace_out=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Fourier interpolation of array ain to shape shapeout.</p>
<p>If shapeout is smaller than ain.shape then Fourier downsampling is
performed</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>ain</code></strong> :&ensp;<code>(&hellip;,Ny,Nx,2) torch.tensor</code></dt>
<dd>Input array</dd>
<dt><strong><code>shapeout</code></strong> :&ensp;<code>(2,) array_like</code></dt>
<dd>Shape of output array</dd>
<dt><strong><code>norm</code></strong> :&ensp;<code>str</code>, optional
<code>{'conserve_val','conserve_norm','conserve_L1'}</code></dt>
<dd>Normalization of output. If 'conserve_val' then array values are preserved
if 'conserve_norm' L2 norm is conserved under interpolation and if
'conserve_L1' L1 norm is conserved under interpolation</dd>
<dt><strong><code>qspace_in</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If True expect a Fourier space input, otherwise (default) expect a
real space input</dd>
<dt><strong><code>qspace_out</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If True return a Fourier space output, otherwise (default) return in
real space</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fourier_interpolate_2d_torch(
    ain, shapeout, norm=&#34;conserve_val&#34;, qspace_in=False, qspace_out=False
):
    &#34;&#34;&#34;
    Fourier interpolation of array ain to shape shapeout.

    If shapeout is smaller than ain.shape then Fourier downsampling is
    performed

    Parameters
    ----------
    ain : (...,Ny,Nx,2) torch.tensor
        Input array
    shapeout : (2,) array_like
        Shape of output array
    norm : str, optional  {&#39;conserve_val&#39;,&#39;conserve_norm&#39;,&#39;conserve_L1&#39;}
        Normalization of output. If &#39;conserve_val&#39; then array values are preserved
        if &#39;conserve_norm&#39; L2 norm is conserved under interpolation and if
        &#39;conserve_L1&#39; L1 norm is conserved under interpolation
    qspace_in : bool, optional
        If True expect a Fourier space input, otherwise (default) expect a
        real space input
    qspace_out : bool, optional
        If True return a Fourier space output, otherwise (default) return in
        real space
    &#34;&#34;&#34;
    dtype = ain.dtype
    inputComplex = iscomplex(ain)
    # Make input complex
    aout = torch.zeros(
        ain.shape[: -2 - int(inputComplex)] + (np.prod(shapeout), 2),
        dtype=dtype,
        device=ain.device,
    )

    # Get input dimensions
    npiyin, npixin = ain.size()[-2 - int(inputComplex) :][:2]
    npiyout, npixout = shapeout

    # Get Fourier interpolation masks
    # PyTorch does not yet do element-wise logic operations, so we have to do
    # this bit in numpy. Additionally, in Windows pytorch does not support
    # bool types so we have to convert this to a unsigned 8-bit integer.
    from .numpy_utils import Fourier_interpolation_masks

    maskin, maskout = [
        torch.from_numpy(x).flatten()
        for x in Fourier_interpolation_masks(npiyin, npixin, npiyout, npixout)
    ]

    # Now transfer over Fourier coefficients from input to output array
    if inputComplex:
        ain_ = ain
    else:
        ain_ = to_complex(ain)

    if not qspace_in:
        ain_ = torch.fft(ain_, signal_ndim=2)

    aout[..., maskout, :] = ain_.flatten(-3, -2)[..., maskin, :]

    # Fourier transform result with appropriate normalization
    if norm == &#34;conserve_val&#34;:
        factor = npiyout * npixout / (npiyin * npixin)
    elif norm == &#34;conserve_norm&#34;:
        factor = np.sqrt(npiyout * npixout / (npiyin * npixin))
    else:
        factor = 1

    # Fourier transform result with appropriate normalization
    aout = factor * aout.reshape(
        ain.shape[: -2 - int(inputComplex)] + tuple(shapeout) + (2,)
    )

    if not qspace_out:
        aout = torch.ifft(aout, signal_ndim=2)

    # Return correct array data type
    if inputComplex:
        return aout
    return aout[re]</code></pre>
</details>
</dd>
<dt id="pyms.utils.torch_utils.fourier_shift_array"><code class="name flex">
<span>def <span class="ident">fourier_shift_array</span></span>(<span>size, posn, dtype=torch.float32, device=device(type='cpu'), units='pixels')</span>
</code></dt>
<dd>
<div class="desc"><p>Create Fourier shift theorem array to (pixel) position given by list posn.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>size</code></strong> :&ensp;<code>array_like</code></dt>
<dd>size of the array (Y,X)</dd>
<dt><strong><code>posn</code></strong> :&ensp;<code>array_like</code></dt>
<dd>can be a K x 2 array to give a K x Y x X shift arrays</dd>
<dt><strong><code>posn</code></strong></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fourier_shift_array(
    size, posn, dtype=torch.float, device=torch.device(&#34;cpu&#34;), units=&#34;pixels&#34;
):
    &#34;&#34;&#34;
    Create Fourier shift theorem array to (pixel) position given by list posn.

    Parameters
    ----------
    size : array_like
        size of the array (Y,X)
    posn : array_like
        can be a K x 2 array to give a K x Y x X shift arrays
    posn
    &#34;&#34;&#34;
    # Get number of dimensions
    nn = len(posn.shape)

    # Get size of array
    y, x = size

    if nn == 1:
        # Make y ramp exp(-2pi i ky y)
        yramp = fourier_shift_array_1d(
            y, posn[0], units=units, dtype=dtype, device=device
        )

        # Make y ramp exp(-2pi i kx x)
        xramp = fourier_shift_array_1d(
            x, posn[1], units=units, dtype=dtype, device=device
        )

        # Multiply both arrays together, view statements for
        # appropriate broadcasting to 2D
        return complex_mul(yramp.view(y, 1, 2), xramp.view(1, x, 2))
    else:
        K = posn.shape[0]
        # Make y ramp exp(-2pi i ky y)
        yramp = torch.empty(K, y, 2, dtype=dtype, device=device)
        ky = (
            2
            * np.pi
            * fftfreq(y, dtype=dtype, device=device).view(1, y)
            * posn[:, 0].view(K, 1)
        )
        if units == &#34;pixels&#34;:
            ky /= y
        yramp[..., 0] = torch.cos(ky)
        yramp[..., 1] = -torch.sin(ky)

        # Make y ramp exp(-2pi i kx x)
        xramp = torch.empty(K, x, 2, dtype=dtype, device=device)
        kx = (
            2
            * np.pi
            * fftfreq(x, dtype=dtype, device=device).view(1, x)
            * posn[:, 1].view(K, 1)
        )
        if units == &#34;pixels&#34;:
            kx /= x

        xramp[..., 0] = torch.cos(kx)
        xramp[..., 1] = -torch.sin(kx)

        # Multiply both arrays together, view statements for
        # appropriate broadcasting to 2D
        return complex_mul(yramp.view(K, y, 1, 2), xramp.view(K, 1, x, 2))</code></pre>
</details>
</dd>
<dt id="pyms.utils.torch_utils.fourier_shift_array_1d"><code class="name flex">
<span>def <span class="ident">fourier_shift_array_1d</span></span>(<span>y, posn, dtype=torch.float32, device=device(type='cpu'), units='pixels')</span>
</code></dt>
<dd>
<div class="desc"><p>Apply Fourier shift theorem for sub-pixel shift to a 1 dimensional array.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fourier_shift_array_1d(
    y, posn, dtype=torch.float, device=torch.device(&#34;cpu&#34;), units=&#34;pixels&#34;
):
    &#34;&#34;&#34;Apply Fourier shift theorem for sub-pixel shift to a 1 dimensional array.&#34;&#34;&#34;
    ramp = torch.empty(y, 2, dtype=dtype, device=device)
    ky = 2 * np.pi * fftfreq(y) * posn
    if units == &#34;pixels&#34;:
        ky /= y
    ramp[..., 0] = torch.cos(ky)
    ramp[..., 1] = -torch.sin(ky)
    return ramp</code></pre>
</details>
</dd>
<dt id="pyms.utils.torch_utils.fourier_shift_torch"><code class="name flex">
<span>def <span class="ident">fourier_shift_torch</span></span>(<span>array, posn, dtype=torch.float32, device=device(type='cpu'), qspace_in=False, qspace_out=False, units='pixels')</span>
</code></dt>
<dd>
<div class="desc"><p>Apply Fourier shift theorem for sub-pixel shifts to array.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>array</code></strong> :&ensp;<code>torch.tensor (&hellip;,Y,X,2)</code></dt>
<dd>Complex array to be Fourier shifted</dd>
<dt><strong><code>posn</code></strong> :&ensp;<code>torch.tensor (K x 2)</code> or <code>(2,)</code></dt>
<dd>Shift(s) to be applied</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fourier_shift_torch(
    array,
    posn,
    dtype=torch.float32,
    device=torch.device(&#34;cpu&#34;),
    qspace_in=False,
    qspace_out=False,
    units=&#34;pixels&#34;,
):
    &#34;&#34;&#34;
    Apply Fourier shift theorem for sub-pixel shifts to array.

    Parameters
    -----------
    array : torch.tensor (...,Y,X,2)
        Complex array to be Fourier shifted
    posn : torch.tensor (K x 2) or (2,)
        Shift(s) to be applied
    &#34;&#34;&#34;
    if not qspace_in:
        array = torch.fft(array, signal_ndim=2)

    array = complex_mul(
        array,
        fourier_shift_array(
            array.size()[-3:-1],
            posn,
            dtype=array.dtype,
            device=array.device,
            units=units,
        ),
    )

    if qspace_out:
        return array

    return torch.ifft(array, signal_ndim=2)</code></pre>
</details>
</dd>
<dt id="pyms.utils.torch_utils.get_device"><code class="name flex">
<span>def <span class="ident">get_device</span></span>(<span>device_type=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Initialize device cuda if available, CPU if no cuda is available.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_device(device_type=None):
    &#34;&#34;&#34;Initialize device cuda if available, CPU if no cuda is available.&#34;&#34;&#34;
    if device_type is None and torch.cuda.is_available():
        device = torch.device(&#34;cuda&#34;)
    elif device_type is None:
        device = torch.device(&#34;cpu&#34;)
    else:
        device = torch.device(device_type)
    return device</code></pre>
</details>
</dd>
<dt id="pyms.utils.torch_utils.iscomplex"><code class="name flex">
<span>def <span class="ident">iscomplex</span></span>(<span>a: torch.Tensor)</span>
</code></dt>
<dd>
<div class="desc"><p>Return True if a is complex, False otherwise.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def iscomplex(a: torch.Tensor):
    &#34;&#34;&#34;Return True if a is complex, False otherwise.&#34;&#34;&#34;
    return a.shape[-1] == 2</code></pre>
</details>
</dd>
<dt id="pyms.utils.torch_utils.sinc"><code class="name flex">
<span>def <span class="ident">sinc</span></span>(<span>x)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the sinc function ie. sin(pi x)/(pi x).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sinc(x):
    &#34;&#34;&#34;Calculate the sinc function ie. sin(pi x)/(pi x).&#34;&#34;&#34;
    y = torch.where(torch.abs(x) &lt; 1.0e-20, torch.tensor([1.0e-20], dtype=x.dtype), x)
    return torch.sin(np.pi * y) / np.pi / y</code></pre>
</details>
</dd>
<dt id="pyms.utils.torch_utils.size_of_bandwidth_limited_array"><code class="name flex">
<span>def <span class="ident">size_of_bandwidth_limited_array</span></span>(<span>shape)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the size of an array after band-width limiting.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def size_of_bandwidth_limited_array(shape):
    &#34;&#34;&#34;Get the size of an array after band-width limiting.&#34;&#34;&#34;
    return list(crop_to_bandwidth_limit_torch(torch.zeros(*shape)).size())</code></pre>
</details>
</dd>
<dt id="pyms.utils.torch_utils.to_complex"><code class="name flex">
<span>def <span class="ident">to_complex</span></span>(<span>real, imag=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Convert real and imaginary tensors to a complex tensor.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_complex(real, imag=None):
    &#34;&#34;&#34;Convert real and imaginary tensors to a complex tensor.&#34;&#34;&#34;
    if imag is None:
        return torch.stack(
            [real, torch.zeros(real.size(), dtype=real.dtype, device=real.device)], -1
        )
    else:
        return torch.stack([real, imag], -1)</code></pre>
</details>
</dd>
<dt id="pyms.utils.torch_utils.torch_c_exp"><code class="name flex">
<span>def <span class="ident">torch_c_exp</span></span>(<span>angle)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate exp(1j*angle).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def torch_c_exp(angle):
    &#34;&#34;&#34;Calculate exp(1j*angle).&#34;&#34;&#34;
    if angle.size()[-1] != 2:
        # Case of a real exponent
        result = torch.zeros(*angle.shape, 2, dtype=angle.dtype, device=angle.device)
        result[re] = torch.cos(angle)
        result[im] = torch.sin(angle)
    else:
        # Case of a complex valued exponent
        exp = torch.exp(-angle[im])
        result = torch.zeros(*angle.shape, dtype=angle.dtype, device=angle.device)
        result[re] = exp * torch.cos(angle[re])
        result[im] = exp * torch.sin(angle[re])
    return result</code></pre>
</details>
</dd>
<dt id="pyms.utils.torch_utils.torch_dtype_to_numpy"><code class="name flex">
<span>def <span class="ident">torch_dtype_to_numpy</span></span>(<span>dtype)</span>
</code></dt>
<dd>
<div class="desc"><p>Convert a torch datatype to a numpy datatype.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def torch_dtype_to_numpy(dtype):
    &#34;&#34;&#34;Convert a torch datatype to a numpy datatype.&#34;&#34;&#34;
    scratch_array = torch.zeros(1, dtype=dtype)
    return scratch_array.cpu().numpy().dtype</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pyms.utils" href="index.html">pyms.utils</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="pyms.utils.torch_utils.amplitude" href="#pyms.utils.torch_utils.amplitude">amplitude</a></code></li>
<li><code><a title="pyms.utils.torch_utils.check_complex" href="#pyms.utils.torch_utils.check_complex">check_complex</a></code></li>
<li><code><a title="pyms.utils.torch_utils.complex_matmul" href="#pyms.utils.torch_utils.complex_matmul">complex_matmul</a></code></li>
<li><code><a title="pyms.utils.torch_utils.complex_mul" href="#pyms.utils.torch_utils.complex_mul">complex_mul</a></code></li>
<li><code><a title="pyms.utils.torch_utils.crop_to_bandwidth_limit_torch" href="#pyms.utils.torch_utils.crop_to_bandwidth_limit_torch">crop_to_bandwidth_limit_torch</a></code></li>
<li><code><a title="pyms.utils.torch_utils.crop_torch" href="#pyms.utils.torch_utils.crop_torch">crop_torch</a></code></li>
<li><code><a title="pyms.utils.torch_utils.crop_window_to_flattened_indices_torch" href="#pyms.utils.torch_utils.crop_window_to_flattened_indices_torch">crop_window_to_flattened_indices_torch</a></code></li>
<li><code><a title="pyms.utils.torch_utils.crop_window_to_periodic_indices" href="#pyms.utils.torch_utils.crop_window_to_periodic_indices">crop_window_to_periodic_indices</a></code></li>
<li><code><a title="pyms.utils.torch_utils.cx_from_numpy" href="#pyms.utils.torch_utils.cx_from_numpy">cx_from_numpy</a></code></li>
<li><code><a title="pyms.utils.torch_utils.cx_to_numpy" href="#pyms.utils.torch_utils.cx_to_numpy">cx_to_numpy</a></code></li>
<li><code><a title="pyms.utils.torch_utils.detect" href="#pyms.utils.torch_utils.detect">detect</a></code></li>
<li><code><a title="pyms.utils.torch_utils.ensure_torch_array" href="#pyms.utils.torch_utils.ensure_torch_array">ensure_torch_array</a></code></li>
<li><code><a title="pyms.utils.torch_utils.fftfreq" href="#pyms.utils.torch_utils.fftfreq">fftfreq</a></code></li>
<li><code><a title="pyms.utils.torch_utils.fourier_interpolate_2d_torch" href="#pyms.utils.torch_utils.fourier_interpolate_2d_torch">fourier_interpolate_2d_torch</a></code></li>
<li><code><a title="pyms.utils.torch_utils.fourier_shift_array" href="#pyms.utils.torch_utils.fourier_shift_array">fourier_shift_array</a></code></li>
<li><code><a title="pyms.utils.torch_utils.fourier_shift_array_1d" href="#pyms.utils.torch_utils.fourier_shift_array_1d">fourier_shift_array_1d</a></code></li>
<li><code><a title="pyms.utils.torch_utils.fourier_shift_torch" href="#pyms.utils.torch_utils.fourier_shift_torch">fourier_shift_torch</a></code></li>
<li><code><a title="pyms.utils.torch_utils.get_device" href="#pyms.utils.torch_utils.get_device">get_device</a></code></li>
<li><code><a title="pyms.utils.torch_utils.iscomplex" href="#pyms.utils.torch_utils.iscomplex">iscomplex</a></code></li>
<li><code><a title="pyms.utils.torch_utils.sinc" href="#pyms.utils.torch_utils.sinc">sinc</a></code></li>
<li><code><a title="pyms.utils.torch_utils.size_of_bandwidth_limited_array" href="#pyms.utils.torch_utils.size_of_bandwidth_limited_array">size_of_bandwidth_limited_array</a></code></li>
<li><code><a title="pyms.utils.torch_utils.to_complex" href="#pyms.utils.torch_utils.to_complex">to_complex</a></code></li>
<li><code><a title="pyms.utils.torch_utils.torch_c_exp" href="#pyms.utils.torch_utils.torch_c_exp">torch_c_exp</a></code></li>
<li><code><a title="pyms.utils.torch_utils.torch_dtype_to_numpy" href="#pyms.utils.torch_utils.torch_dtype_to_numpy">torch_dtype_to_numpy</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.4</a>.</p>
</footer>
</body>
</html>